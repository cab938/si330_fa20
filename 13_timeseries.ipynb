{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time Series Data\n",
    "* We've already seen pandas can handle date/time formats\n",
    "* Time series data adds new manipulation options to our data, and pandas was actually developed with time series data in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resampling \n",
    "* the process of converting a time series from one frequency to another.\n",
    "  * downsampling: going from a high frequency (e.g. daily) to a lower frequency (e.g. weekly)\n",
    "  * upsampling: going from a lower frequency to higher frequency\n",
    "  * remapping: aligning data to a set frequency (e.g. mapping weekly data to sundays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We can create date ranges with\n",
    "pd.date_range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01   -0.702027\n",
       "2018-01-02   -0.562127\n",
       "2018-01-03   -0.389513\n",
       "2018-01-04    0.202224\n",
       "2018-01-05    2.364082\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some sample data\n",
    "dates = pd.date_range(start='1/1/2018', end='05/31/2018')\n",
    "ts = pd.Series(np.random.randn(len(dates)), index=dates)\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.resample.DatetimeIndexResampler object at 0x7fb4f65353c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You need a date or time index on your dataframe to do some resampling\n",
    "# When we resample we need to determine the new frequency we want and how we want to resample\n",
    "# Let's change our daily data down to weekly data\n",
    "resampler=ts.resample('W')\n",
    "resampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-07    0.153167\n",
       "2018-01-14   -0.506203\n",
       "2018-01-21    0.276566\n",
       "2018-01-28    0.146692\n",
       "2018-02-04    0.096839\n",
       "Freq: W-SUN, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just like groupby, this is an object which will do the resampling for us\n",
    "# Since we are downsampling (D->W) we need to decide how to aggregate our datapoints\n",
    "# We are now very used to this!\n",
    "resampler.apply(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Notice the frequency is now W-SUN (weekly beginning on sunday)\n",
    "* When we downsample we are \"binning\" our values and need to determine which end of the bin is open/closed\n",
    "* By default the right side is **closed** for weekly binning, which we did here\n",
    "  * Closed vs. open can be confusing! For example, is an observation at midnight on October 13, 2020 a Tuesday observation, or a Monday observation?\n",
    "  * If you have defined thing as left closed, then it's Monday. If you defined them as right closed, then it's Tuesday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Here's an example\n",
    "* if you have a bunch of time sampled data in seconds and you are downsampling to minutes then:\n",
    "  * if you are **left closed** you are saying \"downsample to minutes where all of the values are **<** the next minute whole number\"\n",
    "  * if you are **right closed** you are saying \"downsample to minutes where all of the values are **<=** the next minute whole number\"\n",
    "* clear as a No.3 Dark Maple Syrup, eh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-10-13 12:59:55    0\n",
       "2020-10-13 12:59:56    1\n",
       "2020-10-13 12:59:57    2\n",
       "2020-10-13 12:59:58    3\n",
       "2020-10-13 12:59:59    4\n",
       "2020-10-13 13:00:00    5\n",
       "2020-10-13 13:00:01    6\n",
       "2020-10-13 13:00:02    7\n",
       "2020-10-13 13:00:03    8\n",
       "Freq: S, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at 9 seconds which cross the minute boundry\n",
    "index = pd.date_range('10/13/2020 12:59:55', periods=9, freq='S')\n",
    "series = pd.Series(range(9), index=index)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-10-13 12:59:00    4\n",
       "2020-10-13 13:00:00    8\n",
       "Freq: T, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we resample this to 1 minute intervals closed on the left \n",
    "# then the first five seconds will be binned to the left value (<)\n",
    "series.resample('1T',closed=\"left\").apply(np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-10-13 12:59:00    5\n",
       "2020-10-13 13:00:00    8\n",
       "Freq: T, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we resample this to 1 minute intervals closed on the right \n",
    "# then the first six seconds will be binned to the left value (<=)\n",
    "series.resample('1T',closed=\"right\").apply(np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=\"https://stackoverflow.com/questions/48340463/how-to-understand-closed-and-label-arguments-in-pandas-resample-method\">https://stackoverflow.com/questions/48340463/how-to-understand-closed-and-label-arguments-in-pandas-resample-method</a>\n",
    "<img src=\"https://i.stack.imgur.com/nX6yv.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00     0\n",
       "2018-01-01 00:01:00     1\n",
       "2018-01-01 00:02:00     2\n",
       "2018-01-01 00:03:00     3\n",
       "2018-01-01 00:04:00     4\n",
       "2018-01-01 00:05:00     5\n",
       "2018-01-01 00:06:00     6\n",
       "2018-01-01 00:07:00     7\n",
       "2018-01-01 00:08:00     8\n",
       "2018-01-01 00:09:00     9\n",
       "2018-01-01 00:10:00    10\n",
       "2018-01-01 00:11:00    11\n",
       "Freq: T, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example, with 12 periods in minute chunks\n",
    "ts = pd.Series(np.arange(12), index=pd.date_range(start='1/1/2018', periods=12,freq='T'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018-01-01 00:00:00    10\n",
       "2018-01-01 00:05:00    35\n",
       "2018-01-01 00:10:00    21\n",
       "Freq: 5T, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do you think will happen if we resample to the nearest whole 5 minute mark but close left?\n",
    "# look at the data, write down in your mind\n",
    "ts.resample(\"5min\", closed='left').apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-12-31 23:55:00     0\n",
       "2018-01-01 00:00:00    15\n",
       "2018-01-01 00:05:00    40\n",
       "2018-01-01 00:10:00    11\n",
       "Freq: 5T, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do you think will happen if we resample to the nearest whole 5 minute mark but close right?\n",
    "# look at the data, write down in your mind\n",
    "ts.resample(\"5min\", closed='right').apply(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:02:00</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:04:00</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:06:00</th>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:08:00</th>\n",
       "      <td>8.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:10:00</th>\n",
       "      <td>10.5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean   max\n",
       "2018-01-01 00:00:00   0.5   1.0\n",
       "2018-01-01 00:02:00   2.5   3.0\n",
       "2018-01-01 00:04:00   4.5   5.0\n",
       "2018-01-01 00:06:00   6.5   7.0\n",
       "2018-01-01 00:08:00   8.5   9.0\n",
       "2018-01-01 00:10:00  10.5  11.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, downresampling really is an aggregation exercise, so you can do all sorts of things\n",
    "# What do you think this does in real language?\n",
    "ts.resample('2min').apply(lambda x: pd.Series({\"mean\":np.mean(x),\"max\":np.max(x)})).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>usr</th>\n",
       "      <th>sys</th>\n",
       "      <th>idl</th>\n",
       "      <th>wai</th>\n",
       "      <th>stl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.602536e+09</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.106</td>\n",
       "      <td>99.347</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.602536e+09</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.312</td>\n",
       "      <td>99.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.602536e+09</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>99.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.602536e+09</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.063</td>\n",
       "      <td>99.812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.602536e+09</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.063</td>\n",
       "      <td>99.812</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          epoch    usr    sys     idl    wai    stl\n",
       "0  1.602536e+09  0.497  0.106  99.347  0.049  0.001\n",
       "1  1.602536e+09  0.438  0.312  99.250  0.000  0.000\n",
       "2  1.602536e+09  0.125  0.125  99.750  0.000  0.000\n",
       "3  1.602536e+09  0.125  0.063  99.812  0.000  0.000\n",
       "4  1.602536e+09  0.125  0.063  99.812  0.000  0.000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inline activity!\n",
    "df=pd.read_csv('datasets/si330_dstat.csv',skiprows=5)\n",
    "df.head()\n",
    "# How do we generate a dataframe which shows the 30 second averages and the \n",
    "# standard deviations of the idl (CPU idle) time?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# With upsampling there is no need to aggregate. \n",
    "\n",
    "# let's create a dataframe, with two weekly indices, and four columns. First the \n",
    "# indicies\n",
    "dates = pd.date_range(start='1/1/2018', periods=2, freq='W')\n",
    "# now let's fill in the DataFrame\n",
    "df = pd.DataFrame(np.random.randn(2,4), index=dates, \n",
    "                  columns=['col1','col2','col3','col4'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Now we upsample from weekly frequency to daily frequency,\n",
    "df_daily = df.resample('D').asfreq()\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# As you notice, there will be NaN values, let's engage in interpolation\n",
    "# Foprward fill or backward fill\n",
    "df.resample('D').ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also choose to only fill a certain number of periods, by using the limit \n",
    "# parameter in the ffill() function. For instance, here, we are limiting to \n",
    "# interpolating three observations\n",
    "df.resample('D').ffill(limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with time series data\n",
    "* we've now seen downsampling and upsampling, and have a better sense of how date ranges are handled in pandas\n",
    "* lets go back to a favorite dataset of ours which has lots of interesting time series data in it and try and explore a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"datasets/AnnArbor-TicketViolation2016.xls\",skiprows=1)\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# First up, let's create a date/time index. We have an issue date column and \n",
    "# an issuetime column\n",
    "def clean_time(x):\n",
    "    issue_time=str(x[\"IssueTime\"])\n",
    "    if len(issue_time) < 4:\n",
    "        issue_time=\"0\"+issue_time\n",
    "    date_time=\"{}{}:{}\".format(\n",
    "        str(x[\"Issue Date \"])[0:11], \n",
    "        issue_time[0:2], \n",
    "        issue_time[-2:], axis=1)\n",
    "    return pd.to_datetime(date_time, format='%Y-%m-%d %H:%M')\n",
    "df=df.set_index(df[[\"Issue Date \",\"IssueTime\"]].apply(clean_time, axis=1))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's plot the fines over the year!\n",
    "import matplotlib.pyplot as plt\n",
    "df[\" Fine \"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# gah! That's meaningless. How would we find signal in that noise?\n",
    "# let's zoom in on a single month, pandas does the \"right thing\" with date/time slicing!\n",
    "df.loc[\"2016-01-01\":\"2016-02-01\", \" Fine \"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This, is, btw, much cooler than it seems at first blush, check this out\n",
    "df.index < \"2016-01-03\"\n",
    "# WOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# so this means we can use date/times as masks!\n",
    "df[df.index<\"2016-02\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's resample this and look at daily totals\n",
    "df.loc[\"2016-01-01\":\"2016-02-01\", \" Fine \"].resample(\"1D\").apply(np.sum).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# January 10th 2016 was a sunday! Looks pretty clear that sundays very few tickets \n",
    "# are given out!\n",
    "# Also, David Bowie died on this day. :(\n",
    "# How do things change if we look at mean values?\n",
    "df.loc[\"2016-01-01\":\"2016-02-01\", \" Fine \"].resample(\"1D\").apply(np.mean).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#We could also look at tickets per hour in a single week\n",
    "df.loc[\"2016-01-11\":\"2016-01-18\", \" Fine \"].resample(\"1H\").apply(len).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# That 13th-14th has some big values, let's zoom in a bit\n",
    "df.loc[\"2016-01-13\":\"2016-01-14\", \" Fine \"].resample(\"15T\").apply(len).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also explore multiple series of data plotted on the same chart by executing plot() on a\n",
    "# dataframe multiple times in a single cell\n",
    "df.loc[\"2016-01-13\":\"2016-01-14\", \" Fine \"].resample(\"15T\").apply(len).plot()\n",
    "df.loc[\"2016-01-13\":\"2016-01-14\", \" Fine \"].resample(\"60T\").apply(len).plot()\n",
    "df.loc[\"2016-01-13\":\"2016-01-14\", \" Fine \"].resample(\"180T\").apply(len).plot()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
